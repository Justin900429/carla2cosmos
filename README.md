# üöó Carla2Cosmos

This repository provides a toolkit for converting CARLA simulation data to the RDS-HQ format used by Cosmos. The converted data can be used with [Cosmos Sample AV Transfer](https://github.com/nvidia-cosmos/cosmos-transfer1/blob/main/examples/inference_cosmos_transfer1_7b_sample_av.md) to generate real-world videos with similar traffic scenarios.

>[!CAUTION]
> This repository **DOES NOT** perform direct style transfer from CARLA to real-world video. Instead, it extracts interactive data like bounding boxes and LiDAR points to help generate real-world videos containing similar traffic scenes and behaviors.

## ‚ñ∂Ô∏è Recording a Clip

Stream and record synchronous CARLA sessions at **30‚ÄØHz**, saving only the essential data needed to convert each clip into the **RDS-HQ** format (used by Cosmos-AV). To record the data, run the `stream_carla.py` script to begin recording:

```bash
python stream_carla.py \
  --town {TOWN_NAME} \
  --num_frames {NUM_FRAMES} \
  --out_dir {DIR_FOR_SAVING_DATA}

# for example
python stream_carla.py \
  --town Town04 \
  --num_frames 600 \
  --out_dir ./data \
```

This will create a 600-frame clip inside `./data/clip_001`. Each recording is saved under:

```plaintext
<out_dir>/clip_<clip_id>/
‚îú‚îÄ‚îÄ ego_pose/              # 4√ó4 SE(3) world‚Üêego transforms (NumPy .npy)
‚îú‚îÄ‚îÄ lidar/                 # LiDAR point clouds with intensity (NumPy .npz)
‚îú‚îÄ‚îÄ camera_front/          # RGB camera frames (PNG images)
‚îú‚îÄ‚îÄ labels_3d/             # 3D dynamic object bounding boxes (JSON)
‚îú‚îÄ‚îÄ hdmap/static_map.xodr  # OpenDRIVE static HD map
‚îú‚îÄ‚îÄ calibration/           # Sensor calibration files (lidar.json, camera_front.json)
‚îú‚îÄ‚îÄ timestamp.json         # Frame timestamps in seconds
‚îú‚îÄ‚îÄ record.log             # Log file of the recording session
‚îî‚îÄ‚îÄ camera_front.mp4       # (Optional) Rendered video if `--make_video` is used
```

Note that:

* only **three blobs are written per frame** ‚Äî the rest are static across the clip.
* All coordinates follow the **right-handed ENU** convention (like Waymo & RDS-HQ).

>[!TIP]
> Run `python stream_carla.py --help` to see all available configuration options, including sensor settings, simulation parameters, and output preferences.

## üóÉÔ∏è Converting to RDS-HQ

To convert the recorded data to the RDS-HQ format, run the `convert_to_rds_hq.py` script:

```bash
export PYTHONPATH=$PYTHONPATH:$(pwd)

python toolkit/convert_carla_to_rds_hq.py \
  --root-dir {DIR_WITH_RECORDING_CLIPS} \
  --out-dir {DIR_FOR_SAVING_DATA}

# for example
python toolkit/convert_carla_to_rds_hq.py \
  --root-dir data \
  --out-dir outputs
```

This will create a directory with the following structure:

```plaintext
<out_dir>/
‚îú‚îÄ‚îÄ pinhole_front/        # Contains video files (.mp4)
‚îú‚îÄ‚îÄ pinhole_intrinsic/    # Contains camera intrinsic parameters
‚îú‚îÄ‚îÄ lidar_raw/            # Contains LiDAR data archives (.tar)
‚îú‚îÄ‚îÄ all_object_info/      # Contains object information data
‚îú‚îÄ‚îÄ timestamp/            # Contains timestamp data
‚îú‚îÄ‚îÄ vehicle_pose/         # Contains vehicle pose data
‚îú‚îÄ‚îÄ pose/                 # Contains pose data
‚îú‚îÄ‚îÄ 3d_road_boundaries/   # Contains 3D road boundary data
‚îú‚îÄ‚îÄ 3d_lanelines/         # Contains 3D lane line data
‚îî‚îÄ‚îÄ 3d_lanes/             # Contains 3D lane data
```

## üé• Rendering from RDS-HQ

>[!TIP]
> The rendering functionality is based on the [cosmos-av-sample-toolkits](https://github.com/nv-tlabs/cosmos-av-sample-toolkits) repository. You can refer to their documentation for more details about the rendering process and options.

To render the HD-Map and Lidar from the RDS-HQ format, run the `render_rds_hq.py` script:

```bash
export PYTHONPATH=$PYTHONPATH:$(pwd)

python toolkit/render_rds_hq.py \
  -d waymo \
  -i {DIR_WITH_RDS_HQ_DATA} \
  -o {DIR_FOR_SAVING_RENDERED_DATA} \
  -c pinhole

# for example
python toolkit/render_rds_hq.py \
  -d waymo -i outputs \
  -o demo_render -c pinhole
```

This will create a directory with the following structure:

```plaintext
<render_dir>/
demo_render/
‚îú‚îÄ‚îÄ lidar/
‚îÇ   ‚îî‚îÄ‚îÄ pinhole_front/    # Contains LiDAR visualization data
‚îî‚îÄ‚îÄ hdmap/
    ‚îî‚îÄ‚îÄ pinhole_front/    # Contains HD map visualization data
```

For multi-camera setups, rendered data is organized in the `lidar` and
`hdmap` directories with the naming convention `pinhole_<camera_name>`.

>[!Note]
> The current version only supports rendering from the front camera.

## üìù Development

Please refer to the [Development](DEVELOPMENT.md) for more details.

## üîí Immunity

All outputs generated by this system, including but not limited to:

* Recorded data
* Rendered visualizations
* Converted formats
* Derived analytics

are provided for research and educational purposes only. Users are responsible for:

1. Verifying the accuracy and suitability of generated outputs for their specific use case
2. Ensuring compliance with local laws and regulations when using the outputs
3. Obtaining necessary permissions for any commercial or public use
4. Acknowledging that the outputs may not be suitable for safety-critical applications

By using this software, you agree to indemnify and hold harmless the developers and contributors from any claims, damages, or liabilities arising from the use of the models or generated outputs.
